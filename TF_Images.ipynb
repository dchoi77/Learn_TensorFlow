{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "* https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Convolutional Neural Network</font>\n",
    "\n",
    "## A simple CNN\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "__Dataset__:\n",
    "\n",
    "```python\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "```\n",
    "\n",
    "* train_images.shape is (50000, 32, 32, 3).\n",
    "* train_labels.shape is (50000, 1).\n",
    "* Entries of train_labels range from 0 to 9 (10 labels).\n",
    "\n",
    "__Model__:\n",
    "\n",
    "```python\n",
    "input_shape = train_images[0].shape\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, 3, activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "```\n",
    "\n",
    "* Since there are 10 class labels, the final output size is 10.\n",
    "* Shapes:\n",
    "    * input: (batch_size, 32, 32, 3)\n",
    "    * after Conv2D: (batch_size, 30, 30, 32)\n",
    "    * after MaxPooling2D: (batch_size, 15, 15, 32)\n",
    "    * after Conv2D: (batch_size, 13, 13, 64)\n",
    "    * after MaxPooling2D: (batch_size, 6, 6, 64)\n",
    "    * after Conv2D: (batch_size, 4, 4, 64)\n",
    "    * after Flatten: (batch_size, 1024)       # 1024 = 4*4*64\n",
    "    * after Dense: (batch_size, 64)\n",
    "    * after Dense: (batch_size, 10)\n",
    "    \n",
    "```python\n",
    "model.compile(optimizer='adam', loss=keras.losses.SparseCategoricalCrossentropy(from_digits=True), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "```\n",
    "\n",
    "* We use the `SparseCategoricalCrossentropy()` loss, since `train_labels.shape[1]` is 1.\n",
    "* If `train_labels.shape[1]` is 10, then we should use the `CategoricalCrossentropy()` loss.\n",
    "* We use `from_digits=True` in `SparseCategoricalCrossentropy()`, since the last dense layer of the model did not use an activation such as `softmax`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ImageDataGenerator\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "__Dataset__:\n",
    "\n",
    "* `train_dir`, `validation_dir`: directories with two subdirectories 'cats' and 'dogs', respectively\n",
    "* `train_cats_dir`: directory with our training cat pictures (the subdirectory 'cats' under 'train_dir')\n",
    "* `train_dogs_dir`: directory with our training dog pictures (the subdirectory 'dogs' under 'train_dir')\n",
    "* `validation_cats_dir`: directory with our validation cat pictures (the subdirectory 'cats' under 'validation_dir')\n",
    "* `validation_dogs_dir`: directory with our validation dog pictures (the subdirectory 'dogs' under 'validation_dir')\n",
    "\n",
    "Load images from the disk, applies rescaling, and resizes the images:\n",
    "```python\n",
    "batch_size = 128\n",
    "IMG_HEIGHT, IMG_WIDTH = 150, 150\n",
    "\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                    rotation_range=45,\n",
    "                    width_shift_range=.15,\n",
    "                    height_shift_range=.15,\n",
    "                    horizontal_flip=True,\n",
    "                    zoom_range=0.5\n",
    "                    )\\\n",
    "    .flow_from_directory(batch_size=batch_size, \n",
    "                         directory=train_dir, \n",
    "                         shuffle=True, \n",
    "                         target_size=(IMG_HEIGHT, IMG_WIDTH), \n",
    "                         class_mode='binary')\n",
    "\n",
    "val_data_gen = ImageDataGenerator(rescale=1./255)\\\n",
    "    .flow_from_directory(batch_size=batch_size,\n",
    "                         directory=validation_dir,\n",
    "                         target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                         class_mode='binary')\n",
    "```\n",
    "\n",
    "* len(train_data_gen) is 16, since the number of training images is 2000 and batch_size is 128.\n",
    "* For i in range(16), \n",
    "    * train_data\\[i\\] which is the _i_-th batch of the training dataset is a tuple of length 2.\n",
    "    * train_data\\[i\\]\\[0\\] is a numpy array of shape (128, 150, 150, 3).\n",
    "    * train_data\\[i\\]\\[1\\] is a numpy array of shape (128, ).\n",
    "\n",
    "\n",
    "__Model__ (binary classifier):\n",
    "\n",
    "```python\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH,3)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(0.2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "```\n",
    "\n",
    "* MaxPooling2D: pool_size=(2, 2) by default.\n",
    "* Shapes:\n",
    "    * input batch: (128, 150, 150, 3)\n",
    "    * after Conv2D: (128, 150, 150, 16)\n",
    "    * after MaxPooling2D: (128, 75, 75, 16)\n",
    "    * after Conv2D: (128, 75, 75, 32)\n",
    "    * after MaxPooling2D: (128, 37, 37, 32)\n",
    "    * after Conv2D: (128, 37, 37, 64)\n",
    "    * after MaxPooling2D: (128, 18, 18, 64)\n",
    "    * after Flatten: (128, 20736)\n",
    "    * after Dense: (128, 512)\n",
    "    * after Dense: (128, 1)\n",
    "    \n",
    "```python\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "Use `fit_generator()` to train the network:\n",
    "\n",
    "```python\n",
    "# total_train is the number of training examples.\n",
    "# total_val is the number of validation examples.\n",
    "history = model.fit_generator(train_data_gen, \n",
    "                              steps_per_epoch=total_train // batch_size\n",
    "                              epochs=15, \n",
    "                              validation_data=val_data_gen,\n",
    "                              validation_steps=total_val // batch_size)                            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning with a TF Hub\n",
    "\n",
    "```python\n",
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "```\n",
    "\n",
    "__Dataset__:\n",
    "\n",
    "```python\n",
    "data_root = tf.keras.utils.get_file('flower_photos',\n",
    "'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "image_data = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\\\n",
    "    .flow_from_directory(data_root, target_size=IMAGE_SHAPE)\n",
    "```\n",
    "\n",
    "* len(image_data) is 115 (=the number of batches)\n",
    "* For i in range(115),\n",
    "    * image_data\\[i\\] (a batch) is a tuple of length 2\n",
    "    * image_data\\[i\\]\\[0\\] (image_batch) has shape of (32, 224, 224, 3). \n",
    "    * image_data\\[i\\]\\[1\\] (label_batch) has shape of (32, 5).\n",
    "    * Each row of image_data\\[i\\]\\[1\\] is in One-Hot encoding.\n",
    "    \n",
    "\n",
    "__Model__:\n",
    "\n",
    "```python\n",
    "classifier_url =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\" #@param {type:\"string\"}\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "])\n",
    "```\n",
    "\n",
    "* The output shape of the ImageNet classifier is (batch_size, 1001).\n",
    "* The result is a 1001 element vector of logits, rating the probability of each class for a given image.\n",
    "\n",
    "```python\n",
    "image_batch, label_batch = image_data[0]\n",
    "\n",
    "result_batch = classifier.predict(image_batch)         # shape: (32, 1001)\n",
    "```\n",
    "\n",
    "__Model (using a headless model)__:\n",
    "\n",
    "```python\n",
    "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\" #@param {type:\"string\"}\n",
    "\n",
    "feature_extractor_layer = hub.KerasLayer(feature_extractor_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "feature_extractor_layer.trainable = False\n",
    "\n",
    "model = tfl.keras.Sequential([\n",
    "    feature_extractor_layer, \n",
    "    layers.Dense(image_data.num_classes)])\n",
    "```\n",
    "\n",
    "* The output of feature_extractor_layer has shape (batch_size, 1280).\n",
    "* image_data.num_classes is 5.\n",
    "* Shapes:\n",
    "    * input: (batch_size, 224, 224, 3)\n",
    "    * after feature_extractor_layer: (batch_size, 1280)\n",
    "    * after Dense: (batch_size, 5)\n",
    "    \n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['acc'])\n",
    "```\n",
    "\n",
    "* Class labels are recorded in One-Hot encoding. Thus we use `CategoricalCrossentropy()` not `SparseCategoricalCrossentropy()`.\n",
    "\n",
    "```python\n",
    "steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
    "\n",
    "history = model.fit_generator(image_data, epochs=15,\n",
    "                              steps_per_epoch=steps_per_epoch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning with a ConvNet\n",
    "\n",
    "```python\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "```\n",
    "\n",
    "__Dataset__:\n",
    "\n",
    "```python\n",
    "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "for image, label in raw_train.take(2):\n",
    "    print((image.shape, image.dtype), (label.numpy(), label.dtype))\n",
    "# Outputs:\n",
    "# (TensorShape([262, 350, 3]), tf.uint8) (1, tf.int64)\n",
    "# (TensorShape([409, 336, 3]), tf.uint8) (1, tf.int64)\n",
    "\n",
    "IMG_SIZE = 160 # All images will be resized to (160, 160).\n",
    "\n",
    "def format_example(image, label):\n",
    "    image = tf.cast(image, tf.float32)/127.5 - 1        # Entries range from -1 to 1.\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label\n",
    "\n",
    "train = raw_train.map(format_example)\n",
    "validation = raw_validation.map(format_example)\n",
    "test = raw_test.map(format_example)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_batches = train.shuffle(1000).batch(BATCH_SIZE)\n",
    "validation_batches = validation.batch(BATCH_SIZE)\n",
    "test_batches = test.batch(BATCH_SIZE)\n",
    "```\n",
    "\n",
    "* Each batch of images has shape of (32, 160, 160, 3).\n",
    "\n",
    "\n",
    "__Model (Feature extraction)__:\n",
    "\n",
    "```python\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "```\n",
    "\n",
    "* Shapes\n",
    "    * input: (batch_size, 160, 160, 3)\n",
    "    * after base_model: (batch_size, 5, 5, 1280)\n",
    "    * after GlobalAveragePooling2D: (batch_size, 1280)\n",
    "    * after Dense: (batch_size, 1)\n",
    "    \n",
    "```python\n",
    "learning_rate = 0.0001\n",
    "initial_epochs = 10\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_batches)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "```\n",
    "\n",
    "__Model (Fine tuning)__:\n",
    "\n",
    "* `len(base_model.layers)` is 155. We set the 100 bottom layers to be untrainable.\n",
    "* We compile the model using a lower learning rate.\n",
    "* `initial_epoch` in model.fit() is an integer at which to start training (useful for resuming a previous training run).\n",
    "* Since `history.epoch` is `[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`, `initial_epoch` is set to 9.\n",
    "\n",
    "```python\n",
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate/10),\n",
    "              metrics=['accuracy'])  \n",
    "\n",
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_batches,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=validation_batches)\n",
    "\n",
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Image Segmentation</font>\n",
    "\n",
    "References: https://www.tensorflow.org/tutorials/images/segmentation\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "import tensorflow_datasets as tfds\n",
    "```\n",
    "\n",
    "__Dataset__: \n",
    "\n",
    "* Each pixel of an image is given a label (0, 1, or 2 in this example). \n",
    "* Think of this as multi-classification where each pixel is being classified into three classes.\n",
    "\n",
    "```python\n",
    "for sample_image_batch, sample_mask_batch in train_dataset.take(1):\n",
    "    break\n",
    "```\n",
    "\n",
    "* `sample_image_batch` is a tf.Tensor with shape=(64,128,128,3).\n",
    "* `sample_mask_batch` is a tf.Tensor with shape=(64,128,128,1).\n",
    "* Each entry of `sample_mask_batch` is 0, 1, or 2.\n",
    "\n",
    "__Model__:\n",
    "\n",
    "* The model being used here is a modified U-Net. A U-Net consists of an encoder (downsampler) and decoder (upsampler). \n",
    "* The encoder uses five intermediate outputs of a pretrained MobileNetV2 model. It will be nontrainable and used for feature extraction.\n",
    "* The decoder uses four upsample blocks implemented in TensorFlow Examples in the Pix2pix tutorial. It will be trainable.\n",
    "\n",
    "```python\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[128,128,3], include_top=False)\n",
    "\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # (64,64,96)\n",
    "    'block_3_expand_relu',   # (32,32,144)\n",
    "    'block_6_expand_relu',   # (16,16,192)\n",
    "    'block_13_expand_relu',  # (8,8,576)\n",
    "    'block_16_project',      # (4,4,320)\n",
    "]\n",
    "layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "down_stack.trainable = False\n",
    "\n",
    "up_stack = [\n",
    "    pix2pix.upsample(512,3),  # 4x4 -> (8,8,512)\n",
    "    pix2pix.upsample(256,3),  # 8x8 -> (16,16,256)\n",
    "    pix2pix.upsample(128,3),  # 16x16 -> (32,32,128)\n",
    "    pix2pix.upsample(64,3),   # 32x32 -> (64,64,64)\n",
    "]\n",
    "\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=[128,128,3])\n",
    "downs = down_stack(inputs)    # list of five tensors\n",
    "\n",
    "concat = tf.keras.layers.Concatenate()\n",
    "x = downs[-1]\n",
    "for i in range(len(up_stack)):\n",
    "    x = concat([up_stack[i](x), downs[-2-i]])\n",
    "    \n",
    "outputs = tf.keras.layers.Conv2DTranspose(3, 3, strides=2, padding='same')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "\n",
    "* Shapes of x:\n",
    "    * before iteration: (4,4,320)\n",
    "    * after i=0: (8,8,1088), concatenated by (8,8,512) and (8,8,576) \n",
    "    * after i=1: (16,16,448), concatenated by (16,16,256) and (16,16,192)\n",
    "    * after i=2: (32,32,272), concatenated by (32,32,128) and (32,32,144)\n",
    "    * after i=3: (64,64,160), concatenated by (64,64,64) and (64,64,96)\n",
    "    \n",
    "* outputs.shape is (128,128,3), since there are three possible labels for each pixel.\n",
    "\n",
    "* If `x` is a tensor of shape (a,b,c), then `Conv2DTranspose(n, 3, strides=2, padding='same')(x)` returns a tensor of shape (2a,2b,n).\n",
    "\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit(train_dataset, epochs=20,\n",
    "                          steps_per_epoch=57,\n",
    "                          validation_steps=11,\n",
    "                          validation_data=test_dataset)\n",
    "```\n",
    "\n",
    "See the result of a test image:\n",
    "\n",
    "```python\n",
    "for image_batch, mask_batch in test_dataset.take(1):\n",
    "    image, mask = image_batch[0], mask_batch[0]\n",
    "    pred_mask = model.predict(image[tf.newaxis,])[0]          # shape: (128,128,3)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)                 # shape: (128,128)\n",
    "    pred_mask = pred_mask[...,tf.newaxis]                     # shape: (128,128,1)\n",
    "```\n",
    "\n",
    "Next, plot `image`, `mask`, and `pred_mask`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
